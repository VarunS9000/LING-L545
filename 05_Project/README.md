# Project

The intent of this project is threefolds. First is to successfully present a way to build a multi-label (12 labels) text classification model. Secondly to empirically show LSTMs work better with sequential data such as texts than CNNs (Convolutional Neural Network) or MLPs (Multi Layer Perceptron), especially while performing an intensive task such as multi-label text classification. Thirdly, to empirically show that feature representation using word-embeddings are better than feature representation using  Bag of Words in terms of providing good accuracy.
